# General Agent Profile
# A versatile configuration for general-purpose agent task execution
# Includes web browsing, code execution, file operations, and fundamental tools

# Default agent configurations
agents:
  # Atomizer: Fast decision-making with Gemini Flash
  atomizer:
    llm:
      model: fireworks_ai/accounts/fireworks/models/glm-4p6
      temperature: 0.4
      max_tokens: 8000
    # Load atomizer seed prompt and demos for improved task classification
    signature_instructions: "prompt_optimization.prompts.seed_prompts.atomizer_seed:ATOMIZER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.atomizer_seed:ATOMIZER_DEMOS"
    adapter_type: chat

  # Planner: Strategic planning with Gemini Flash
  planner:
    llm:
      model: openrouter/google/gemini-2.5-flash-preview-09-2025
      temperature: 0.4
      max_tokens: 32000
    # Load planner seed prompt and demos for improved task decomposition
    signature_instructions: "prompt_optimization.prompts.seed_prompts.planner_seed:PLANNER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.planner_seed:PLANNER_DEMOS"
    adapter_type: chat
    agent_config:
      max_subtasks: 12

    toolkits:
      - class_name: WebSearchToolkit
        enabled: true
        toolkit_config:
          model: openai/gpt-5-mini
          # No search_engine = native OpenAI search
          max_results: 5
          search_context_size: high
          temperature: 1.0  # Required for GPT-5 reasoning models
          max_tokens: 128_000  # Required for GPT-5 reasoning models

  # Default Executor (fallback for unmapped task types)
  executor:
    llm:
      model: openrouter/anthropic/claude-sonnet-4.5
      temperature: 0.6
      max_tokens: 128_000
    prediction_strategy: react
    # Load executor seed prompt and demos for improved task execution
    signature_instructions: "prompt_optimization.prompts.seed_prompts.executor_seed:EXECUTOR_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.executor_seed:EXECUTOR_DEMOS"
    adapter_type: chat
    agent_config:
      max_executions: 10
    # Default fundamental toolkits
    toolkits:
      - class_name: WebSearchToolkit
        enabled: true
        toolkit_config:
          model: openai/gpt-5-mini
          # No search_engine = OpenRouter native search
          search_context_size: high
          temperature: 1.0  # Required for GPT-5 reasoning models
          max_tokens: 128_000  # Required for GPT-5 reasoning models

  # Aggregator: Synthesis with Gemini Flash
  aggregator:
    llm:
      model: fireworks_ai/accounts/fireworks/models/glm-4p6
      temperature: 0.6
      max_tokens: 180_000
    # Load aggregator seed prompt for improved result synthesis
    adapter_type: chat
    signature_instructions: "prompt_optimization.prompts.seed_prompts.aggregator_seed:AGGREGATOR_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.aggregator_seed:AGGREGATOR_DEMOS"

  # Verifier: Validation with Gemini Flash
  verifier:
    llm:
      model: openrouter/google/gemini-2.5-flash-preview-09-2025
      temperature: 0.0
      max_tokens: 16000
    # Load verifier seed prompt and demos for improved output validation
    signature_instructions: "prompt_optimization.prompts.seed_prompts.verifier_seed:VERIFIER_PROMPT"
    demos: "prompt_optimization.prompts.seed_prompts.verifier_seed:VERIFIER_DEMOS"
    adapter_type: chat  
# Task-aware agent mapping for executor
agent_mapping:
  executors:
    # RETRIEVE: Fast data fetching with minimal reasoning
    # Use cases: "price of bitcoin", "get market cap", "fetch token holders"
    RETRIEVE:
      llm:
        model: fireworks_ai/accounts/fireworks/models/glm-4p6  # Fast & cheap for simple queries
        temperature: 0.7  # Deterministic data retrieval
        max_tokens: 128_000  # Sufficient for data responses
      prediction_strategy: react
      # Load RETRIEVE-specific seed prompt and demos
      signature_instructions: "prompt_optimization.prompts.seed_prompts.executor_retrieve_seed:EXECUTOR_RETRIEVE_PROMPT"
      demos: "prompt_optimization.prompts.seed_prompts.executor_retrieve_seed:EXECUTOR_RETRIEVE_DEMOS"
      agent_config:
        max_executions: 6  # Fewer iterations for simple retrievals
      adapter_type: chat
      # Default fundamental toolkits
      toolkits:
        - class_name: WebSearchToolkit
          enabled: true
          toolkit_config:
            model: openai/gpt-5-mini
            # No search_engine = OpenRouter native search
            search_context_size: high
            temperature: 1.0  # Required for GPT-5 reasoning models
            max_tokens: 128_000  # Required for GPT-5 reasoning models
    # THINK: Deep market analysis, pattern recognition, insights
    # Use cases: "analyze market sentiment", "identify trends", "compare tokens"
    THINK:
      llm:
        model: fireworks_ai/accounts/fireworks/models/glm-4p6  # Best reasoning
        temperature: 0.2  # Balanced creativity + accuracy
        max_tokens: 16000  # Large context for complex reasoning
      prediction_strategy: react
      adapter_type: chat
      # Load THINK-specific seed prompt and demos
      signature_instructions: "prompt_optimization.prompts.seed_prompts.executor_think_seed:EXECUTOR_THINK_PROMPT"
      demos: "prompt_optimization.prompts.seed_prompts.executor_think_seed:EXECUTOR_THINK_DEMOS"
      agent_config:
        max_executions: 12  # Multiple iterations for deep analysis
      # All data sources + web search + code execution - HOMOGENIZED configs
      toolkits:
        - class_name: WebSearchToolkit
          enabled: true
          toolkit_config:
            model: openai/gpt-5-mini
            # No search_engine = OpenRouter native search
            search_context_size: high
            temperature: 1.0  # Required for GPT-5 reasoning models
            max_tokens: 128_000  # Required for GPT-5 reasoning models

        - class_name: FileToolkit  # Save insights
          enabled: true
          toolkit_config:
            enable_delete: false
            max_file_size: 10485760  # HOMOGENIZED: 10MB standard

    # WRITE: Professional reports, summaries, documentation
    # Use cases: "write analysis report", "summarize findings", "create documentation"
    WRITE:
      llm:
        model: fireworks_ai/accounts/fireworks/models/glm-4p6  # Best writing quality
        temperature: 0.3  # More creative for engaging writing
        max_tokens: 16000  # Long-form content
      prediction_strategy: react
      adapter_type: chat
      # Load WRITE-specific seed prompt and demos
      signature_instructions: "prompt_optimization.prompts.seed_prompts.executor_write_seed:EXECUTOR_WRITE_PROMPT"
      demos: "prompt_optimization.prompts.seed_prompts.executor_write_seed:EXECUTOR_WRITE_DEMOS"
      agent_config:
        max_executions: 8  # Moderate iterations for refinement
      # File I/O + reference data + research - HOMOGENIZED configs
      toolkits:
        - class_name: FileToolkit  # PRIMARY: Save reports
          enabled: true
          toolkit_config:
            enable_delete: false
            max_file_size: 10485760  # HOMOGENIZED: 10MB standard
# Runtime configuration
runtime:
  max_depth: 1
  verbose: true
  enable_logging: true
  log_level: INFO
  timeout: 300

# Resilience
resilience:
  retry:
    enabled: true
    max_attempts: 5
    strategy: exponential_backoff
    base_delay: 2.0
    max_delay: 60.0

  circuit_breaker:
    enabled: true
    failure_threshold: 5
    recovery_timeout: 120.0
    half_open_max_calls: 3

  checkpoint:
    enabled: true
    storage_path: ${oc.env:ROMA_CHECKPOINT_PATH,.checkpoints}
    max_checkpoints: 20
    max_age_hours: 48.0
    compress_checkpoints: true
    verify_integrity: true

# Storage
storage:
  base_path: ${oc.env:STORAGE_BASE_PATH,/opt/sentient}
  max_file_size: 104857600  # 100MB

  postgres:
    enabled: ${oc.env:POSTGRES_ENABLED,true}
    connection_url: ${oc.env:DATABASE_URL,postgresql+asyncpg://localhost/roma_dspy}
    pool_size: 10
    max_overflow: 20

# Observability
observability:
  mlflow:
    enabled: ${oc.env:MLFLOW_ENABLED,false}
    tracking_uri: ${oc.env:MLFLOW_TRACKING_URI,http://mlflow:5000}
    experiment_name: ROMA-General-Agent
    log_traces: true
    log_compiles: true
    log_evals: true

# Logging
logging:
  level: ${oc.env:LOG_LEVEL,INFO}
  log_dir: ${oc.env:LOG_DIR,logs}
  console_format: detailed
  file_format: json
  serialize: true
  rotation: 500 MB
  retention: 90 days
  colorize: true
  backtrace: true
  diagnose: false
